{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Survey Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions to clean code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pilot_data(starting_df):\n",
    "    \"\"\"Clean the pilot qualtrics survey data for the clean pilot data set\"\"\"\n",
    "    # The first row is the row that specifies more of the column header\n",
    "    # just grab the responses\n",
    "    data = starting_df.iloc[1:, ].copy()\n",
    "    \n",
    "    # drop unnessary columms\n",
    "    data.drop(columns = [\"RecipientLastName\",\n",
    "                         \"RecipientFirstName\",\n",
    "                         'RecipientEmail',\n",
    "                         'ExternalReference',\n",
    "                         'LocationLatitude', \n",
    "                         'LocationLongitude',\n",
    "                         'IPAddress', \n",
    "                         'DistributionChannel', \n",
    "                         'Status'], inplace = True)\n",
    "    # rename columns to make sense\n",
    "    data.rename({\"Q1\": \"gender\",\n",
    "                 \"Q2\": \"age\",\n",
    "                 \"Q3_1\": \"enjoy_reading\",\n",
    "                 \"Q4\" : \"books\",\n",
    "                 \"Q5_1\" : \"sci_fi\",\n",
    "                 \"Q6\" : \"attention_check1\",\n",
    "                 \"Q7\" : \"attention_check2\",\n",
    "                 \"Q8\" : \"attention_check3\",\n",
    "                 \"Q9_1\" : \"competent\",\n",
    "                 \"Q10_1\" : \"warm\",\n",
    "                 \"Q11_1\" : \"capable\",\n",
    "                 \"Q12_1\" : \"well_intentioned\",\n",
    "                 \"Q13_1\" : \"respect\",\n",
    "                 \"Q14\" : \"recognize_passage\",\n",
    "                 \"Duration (in seconds)\": 'duration',\n",
    "                 \"Passage Gender\": \"passage_gender\"}, axis = 'columns', inplace = True)\n",
    "    \n",
    "    # change the passage gender column values to match with final data\n",
    "    data.loc[data['passage_gender'] == 'Male', 'passage_gender'] = 'PassageM'\n",
    "    data.loc[data['passage_gender'] == 'Female', 'passage_gender'] = 'PassageF'\n",
    "    data.columns = data.columns.str.lower()\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(starting_df):\n",
    "    \"\"\"Clean the final qualtrics survey data for the final data set\"\"\"\n",
    "    # The first row is the row that specifies more of the column header\n",
    "    # just grab the responses\n",
    "    data = starting_df.iloc[1:,]\n",
    "    \n",
    "    # grab the correct data for outcome measures \n",
    "    # we have to fillna because of our blocking on gender\n",
    "    competent = data['10_1'].fillna(data['10_1.1']) \n",
    "    warm = data['11_1'].fillna(data['11_1.1']) \n",
    "    capable = data['12_1'].fillna(data['12_1.1'])\n",
    "    well_intentioned = data['13_1'].fillna(data['13_1.1']) \n",
    "    respect = data['14_1'].fillna(data['14_1.1']) \n",
    "    \n",
    "    # grab some columns for the final df\n",
    "    df = data.iloc[:,:17].copy()\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    df.drop(columns = [\"RecipientLastName\",\n",
    "                       \"RecipientFirstName\",\n",
    "                       'RecipientEmail',\n",
    "                       'ExternalReference',\n",
    "                       'LocationLatitude', \n",
    "                       'LocationLongitude'], inplace = True)\n",
    "    df.rename({'Duration (in seconds)': 'duration'}, axis = 'columns', inplace = True)\n",
    "    \n",
    "    # add columns to our df for our covariates\n",
    "    df['gender'] = data['1'].copy()\n",
    "    df['age'] = data['2'].copy()\n",
    "    df['education'] = data['3'].copy()\n",
    "    df['enjoy_reading'] = data['4_1'].copy()\n",
    "    df['books'] = data['5'].copy()\n",
    "    df['sci_fi'] = data['6_1'].copy()\n",
    "    \n",
    "    # add attention check columns\n",
    "    # we need to fillna because of how we blocked on gender\n",
    "    df['attention_check1'] = data['7'].copy().fillna(data['7.1'])\n",
    "    df['attention_check2'] = data['8'].copy().fillna(data['8.1'])\n",
    "    df['attention_check3'] = data['9'].copy().fillna(data['9.1'])\n",
    "    \n",
    "    # columns of how much a user correctly answered attention check questions\n",
    "    df['check1_pass'] = (df['attention_check1'] == 'smile')*1\n",
    "    df['check2_pass'] = (df['attention_check2'] == 'A world without robots')*1\n",
    "    df['check3_pass'] = (df['attention_check3'] == \"A news article written about the interviewee's retirement\")*1\n",
    "    df['check_pass'] = df['check1_pass'] + df['check2_pass'] + df['check3_pass']\n",
    "    \n",
    "    # add in our outcome measures into our dataset\n",
    "    df['competent'] = competent \n",
    "    df['warm'] = warm \n",
    "    df['capable'] = capable\n",
    "    df['well_intentioned'] = well_intentioned \n",
    "    df['respect'] = respect \n",
    "    \n",
    "    # add column on if they recognize the passage or not\n",
    "    df['recognize_passage'] = data['15'].copy()\n",
    "    \n",
    "    # drop more unnecessary columns\n",
    "    df.drop(columns = ['IPAddress', 'DistributionChannel', 'Status'], inplace = True)\n",
    "    \n",
    "    # find the gender blocking columns and create a new dataframe for it\n",
    "    gender_blocking_df = data.loc[:, ['FL_27_DO', 'FL_30_DO', 'FL_33_DO', 'FL_36_DO', 'FL_39_DO', 'FL_19_DO',\n",
    "       'FL_15_DO', 'FL_9_DO']].copy()\n",
    "    \n",
    "    # rename the columns to make it understandable\n",
    "    gender_blocking_df.rename(columns = {'FL_27_DO': 'Other_Block',\n",
    "                                     'FL_30_DO': 'Gender_Fluid_Block',\n",
    "                                     'FL_33_DO': 'Nonbinary_Block',\n",
    "                                     'FL_36_DO': 'Transgender_Block',\n",
    "                                     'FL_39_DO': 'T_Male_Block',\n",
    "                                     'FL_19_DO': 'T_Female_Block',\n",
    "                                     'FL_15_DO': 'C_Male_Block',\n",
    "                                     'FL_9_DO' : 'C_Female_Block'}, inplace = True)\n",
    "    \n",
    "    # create a column that specifies what passage the respondent got\n",
    "    gender_blocking_df['Passage_Gender'] = gender_blocking_df.stack().tolist()\n",
    "    \n",
    "    # combine the dataframe with covariates, attention check and ratings \n",
    "    # with the gender blocking passage genderdataframe\n",
    "    final_df = pd.concat([df,gender_blocking_df], axis = 1)\n",
    "    \n",
    "    # make all the column headers to be lowercase\n",
    "    final_df.columns = final_df.columns.str.lower()\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pilot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw_pilot_data\n",
    "pilot_raw = pd.read_csv('./raw_pilot_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean pilot data\n",
    "pilot_clean = clean_pilot_data(pilot_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['startdate', 'enddate', 'progress', 'duration', 'finished',\n",
       "       'recordeddate', 'responseid', 'userlanguage', 'gender', 'age',\n",
       "       'enjoy_reading', 'books', 'sci_fi', 'attention_check1',\n",
       "       'attention_check2', 'attention_check3', 'competent', 'warm', 'capable',\n",
       "       'well_intentioned', 'respect', 'recognize_passage', 'passage_gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the columns of pilot data\n",
    "pilot_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the shape of the data - 27 responses\n",
    "pilot_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output clean pilot data to test_and_analysis folder\n",
    "pilot_clean.to_csv('../tests_and_analysis/pilot_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Study - mturk and email & slack respondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load raw_mturk_data and raw_slack_and_email_data\n",
    "mturk = pd.read_excel('./raw_mturk_data.xlsx')\n",
    "email_slack = pd.read_excel('./raw_slack_and_email_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean mturk data\n",
    "final_mturk = clean_data(mturk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of incomplete repsonse from mturk\n",
    "sum(final_mturk['finished'] == 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean slack and email data\n",
    "slack_email_df = clean_data(email_slack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of incomplete responses from slack and email\n",
    "sum(slack_email_df['finished'] == 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slack and email without the incomplete data\n",
    "final_slack_email = slack_email_df.loc[slack_email_df['finished'] == 'True',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a column for the source of these responses\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "final_mturk['source'] = 'mturk'\n",
    "final_slack_email['source'] = 'slack_email'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the final clean survey data\n",
    "final_df = pd.concat([final_mturk, final_slack_email])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['startdate', 'enddate', 'progress', 'duration', 'finished',\n",
       "       'recordeddate', 'responseid', 'userlanguage', 'gender', 'age',\n",
       "       'education', 'enjoy_reading', 'books', 'sci_fi', 'attention_check1',\n",
       "       'attention_check2', 'attention_check3', 'check1_pass', 'check2_pass',\n",
       "       'check3_pass', 'check_pass', 'competent', 'warm', 'capable',\n",
       "       'well_intentioned', 'respect', 'recognize_passage', 'other_block',\n",
       "       'gender_fluid_block', 'nonbinary_block', 'transgender_block',\n",
       "       't_male_block', 't_female_block', 'c_male_block', 'c_female_block',\n",
       "       'passage_gender', 'source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the columns of the final clean survey data\n",
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 37)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the shape of final clean survey data\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output clean final data to test_and_analysis folder\n",
    "final_df.to_csv('../tests_and_analysis/final_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
